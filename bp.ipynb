{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import statistics\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import math \n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from snntorch import functional as SF\n",
    "import csv \n",
    "import pandas as pd\n",
    "# dataset citation: https://www.kaggle.com/datasets/dmitryshkadarevich/branch-prediction?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "filepath = \"Datasets\\\\bp_data\\\\I04.csv\" \n",
    "file = pd.read_csv(filepath)\n",
    "\n",
    "print(type(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, beta, n_actions, num_steps, batch_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.num_steps = num_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.input_width = num_inputs\n",
    "\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "        self.fc3 = nn.Linear(num_hidden, n_actions)\n",
    "        self.lif3 = snn.Leaky(beta=beta)\n",
    "        \n",
    "        # self.spikes_hist = []\n",
    "        #self.spikes_hist = torch.empty(0).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "\n",
    "        # Record the final layer\n",
    "        spk1_rec = []\n",
    "        spk2_rec = []\n",
    "        spk3_rec = []\n",
    "        mem3_rec = [] \n",
    "        for step in range(self.num_steps):\n",
    "            cur1 = self.fc1(x[0:self.batch_size, step, 0:self.input_width]) \n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            spk1_rec.append(spk1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "            cur3 = self.fc3(spk2)\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "            spk3_rec.append(spk3)\n",
    "            mem3_rec.append(mem3)\n",
    "        \n",
    "        spk1_rec = torch.stack(spk1_rec)\n",
    "        spk2_rec = torch.stack(spk2_rec)\n",
    "        spk3_rec = torch.stack(spk3_rec)\n",
    "        self.spikes_hist = [spk1_rec, spk2_rec, spk3_rec]\n",
    "\n",
    "        mem3_rec = torch.stack(mem3_rec)\n",
    "\n",
    "        return spk3_rec, mem3_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_spike(spikes): \n",
    "    output = []\n",
    "    unpacked = []\n",
    "    for item in spikes: \n",
    "        # time * batch * neurons \n",
    "        # sum in time and neuron dimensions \n",
    "        unpacked.append(item.sum(0).sum(-1))\n",
    "        #gives spike count by batch \n",
    "        #print(item.sum(0).sum(-1).size())\n",
    "    for i in range(unpacked[0].size()[0]): \n",
    "        count = 0\n",
    "        for item in unpacked:\n",
    "            count += item[i] \n",
    "        \n",
    "        output.append(count)\n",
    "    return torch.stack(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(data, model, num_epochs, loss, optimizer, batch_size, device):\n",
    "    loss_hist = []\n",
    "    dtype = torch.float\n",
    "    loss_by_epoch = [] \n",
    "\n",
    "    # Outer training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = [] \n",
    "        #iter_counter = 0\n",
    "\n",
    "        # Minibatch training loop\n",
    "        for i, (item, targets) in enumerate(iter(data)):\n",
    "            targets = targets[0:batch_size, 1:2]\n",
    "            targets = targets.flatten()\n",
    "\n",
    "            targets = targets.type(torch.long)\n",
    "\n",
    "            # forward pass\n",
    "            model.train()\n",
    "            spk_rec, mem_rec = model(item)\n",
    "\n",
    "            # initialize the loss & sum over time\n",
    "            loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "\n",
    "            loss_val = torch.sum(loss(mem_rec, targets))\n",
    "\n",
    "            # Gradient calculation + weight update\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Store loss history for future plotting\n",
    "            loss_hist.append(loss_val.item())\n",
    "            epoch_loss.append(loss_val.item())\n",
    "\n",
    "            # Calculate accuracy without SF.accuracy_rate\n",
    "            pred = torch.argmax(mem_rec.detach(), dim=1)\n",
    "            accuracy = metrics.accuracy_score(targets.detach(), pred)\n",
    "\n",
    "            # Print accuracy\n",
    "            if loss_val.item() > 0.001:\n",
    "                if i % 2 == 0:\n",
    "                    print(f\"Epoch {epoch}, Iteration {i}, Train Loss: {loss_val.item():.2f}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "            else:\n",
    "                if i % 20 == 0:\n",
    "                    print(f\"Epoch {epoch}, Iteration {i}, Train Loss: {loss_val.item():.2f}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "        loss_by_epoch.append(epoch_loss)\n",
    "    \n",
    "    return (loss_hist, loss_by_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loop(data_eval, model, net, batch_size):\n",
    "    f1_score = []\n",
    "    accuracy = []\n",
    "    preds = [] \n",
    "    spike_counts = []\n",
    "    net.eval()\n",
    "    for item, targets in iter(data_eval):\n",
    "        targets = targets[0:batch_size, 1:2]\n",
    "        targets = targets.flatten()\n",
    "        targets = targets.type(torch.long)\n",
    "\n",
    "        #Get predictions\n",
    "        spk_rec, mem_rec = model(item)\n",
    "        spike_counts = spike_counts + count_spike(spk_rec).tolist()\n",
    "\n",
    "        #Convert to binary \n",
    "        pred = torch.argmax(mem_rec.detach(), dim=1)\n",
    "        # Calculate metrics \n",
    "\n",
    "\n",
    "\n",
    "        f1_score.append(metrics.f1_score(targets.detach(), pred))\n",
    "        accuracy.append(metrics.accuracy_score(targets.detach(), pred))\n",
    "        preds.extend(pred.tolist())\n",
    "\n",
    "    net.train()\n",
    "    return(spike_counts, preds, f1_score, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 80 # modify\n",
    "num_steps = 1 # modify \n",
    "batch_size = 128 # may be modified \n",
    "num_hidden = 128\n",
    "num_outputs = 2  \n",
    "beta = .95 \n",
    "# self, n_observations, num_hidden, beta, n_actions, num_steps, batch_size, input_width: int=80, use_mempot = False\n",
    "net = Net(num_inputs, num_hidden, beta, num_outputs, num_steps, batch_size, )\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moesnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
